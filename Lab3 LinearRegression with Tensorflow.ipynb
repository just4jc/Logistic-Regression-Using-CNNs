{
    "metadata": {
        "language_info": {
            "file_extension": ".py", 
            "mimetype": "text/x-python", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }, 
            "pygments_lexer": "ipython3", 
            "name": "python", 
            "version": "3.5.2", 
            "nbconvert_exporter": "python"
        }, 
        "kernelspec": {
            "display_name": "Python 3.5 (Experimental) with Spark 1.6 (Unsupported)", 
            "language": "python", 
            "name": "python3"
        }
    }, 
    "cells": [
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "## Linear Regression with Tensorflow"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### Import the libraries\nThis is linear regression learning algorithm example using <em><b>TensorFlow</b></em> library. Besides, we also need to import the <em><b>numpy</b></em> and <em><b>matplotlib</b></em>.<br>\n<p>\n<div class=\"btn-group\">\n  <a class=\"btn btn-info\" href=\"http://www.numpy.org\" style=\"border-radius: 2px\">numpy</button>\n  <a class=\"btn btn-info\" href=\"https://www.tensorflow.org/\" style=\"border-radius: 2px\">TensorFlow</button>\n  <a class=\"btn btn-info\" href=\"https://matplotlib.org/\" style=\"border-radius: 2px\">matplotlib</button>\n</div>\n</p>"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 1, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# A linear regression learning algorithm example using TensorFlow library.\nimport tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 1. Set the parameter\nThe below snippet shows the setting of <b><em>learning rate</em></b>, <b><em>training epoch</em></b> and <b><em>display step</em></b> in this sample. Choosing right learning rate is especially important since it has impact on the speed of gradient descent, if the learning rate you choose is too large, you will probably never reach the minimum of loss.<br>\n<a class=\"btn btn-info\" href=\"https://www.coursera.org/learn/machine-learning/lecture/3iawu/gradient-descent-in-practice-ii-learning-rate\" style=\"border-radius: 2px\">learning rate</button>"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 2, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Hyper Parameters\nlearning_rate = 0.01\ntraining_epochs = 1000\ndisplay_step = 100"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 3, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Create an empty array called \"cost_history\" for later use, the shape is [1], data type is \"float\".\ncost_history = np.empty(shape=[1],dtype=float)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 2. Create the training data and testing data"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 4, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Training Data \ntrain_X = np.asarray([2.1,3.3,4.4,5.5,6.71,6.93,4.168,9.779,6.182,7.59,2.167,\n                         7.042,10.791,5.313,7.997,5.654,9.27,3.1,2.4])\ntrain_Y = np.asarray([1.1,1.7,2.76,2.09,3.19,1.694,1.573,3.366,2.596,2.53,1.221,\n                         2.827,3.465,1.65,2.904,2.42,2.94,1.3,2.8])\n\n# Tresting Data \ntest_X = np.asarray([6.83, 4.668, 8.9, 7.91, 5.7, 8.7, 3.1, 2.1])\ntest_Y = np.asarray([1.84, 2.273, 3.2, 2.831, 2.92, 3.24, 1.35, 1.03])\n\n# Create a variable which is used to put the number of rows of train_X\nn_samples = train_X.shape[0]"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 3. Create placeholders for tf Graph Inputs\nIn this step, we are going to create two placeholders for training and testing data. <br>\nTensorFlow provides a placeholder operation that must be fed with data on execution, and its value must be fed using the <b>feed_dict</b> optional argument to <b>Session.run()</b>, <b>Tensor.eval()</b>, or <b>Operation.run()</b>. For this example, we need to set the data type to \"float\", because the training data and testing date are \"float\" type."
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 5, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Create placeholders for tf Graph Inputs, called \"X\" and \"Y\", with tf.placeholder, the datatype should be \"float\"\nX = tf.placeholder(\"float\")\nY = tf.placeholder(\"float\")"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 4. Set Weights(W) and Biases(b)\nIn this step we are going to set the initial Weights and Biases for the model through using the TensorFlow varible and randn() funtion in numpy.random module.<br>\nA <b>tf.Variable</b> represent a tensor whose value can be changed by running ops on it. Internally, a <b>tf.Variable</b> stores a persistent tensor. Specific ops allow you to read and modify the values of this tensor. These modifications are visible across multiple <b>tf.Session</b>s(which will be mentioned later), so multiple workers can see the same values for a <b>tf.Variable</b>.<br>\n<a class=\"btn btn-info\" href=\"https://www.tensorflow.org/programmers_guide/variables\" style=\"border-radius: 2px\">TensorFlow variable</button>"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 6, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Set model weights(W) and biases(b) with tf.Variable\nrng = np.random\nW = tf.Variable(rng.randn(), name=\"weight\")\nb = tf.Variable(rng.randn(), name=\"bias\")"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "<button type=\"button\" class=\"btn btn-info\" data-toggle=\"collapse\" data-target=\"#hint1\">\nClick here for the more information</button>\n<div id=\"hint1\" class=\"collapse\">\n<p style=\"color:#0066ff\"><b>W = tf.Variable(<em>initial-value, name = \"optional name\"</em>)</b><br>\n<small><b>initial-value:</b>The initial value defines the type and shape of the variable.</small><br>\n<small><b>name:</b> in this exmaple, we can use \"weight\" andt \"bias\".</small><br>\n</p>\n</div>"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 5. Linear Regerssion implementation\nLinear Regression Implementation is pretty straight forward. Three lines of code is all that is required. <br>\n- 1.First line will multiply features matrix to weights matrix and can be used for prediction.\n- 2.The second line is cost or loss function (squared error of regression line).\n- 3.Finally the third line performs one step of gradient descent optimization to minimize the cost function.\n<br>\n\n<div class=\"btn-group\">\n  <a class=\"btn btn-info\" href=\"https://www.tensorflow.org/api_docs/python/tf/add\" style=\"border-radius: 2px\">tf.add</button>\n  <a class=\"btn btn-info\" href=\"https://www.tensorflow.org/api_docs/python/tf/multiply\" style=\"border-radius: 2px\">tf.multiply</button>\n  <a class=\"btn btn-info\" href=\"https://www.tensorflow.org/api_docs/python/tf/pow\" style=\"border-radius: 2px\">tf.pow</button>\n  <a class=\"btn btn-info\" href=\"https://www.tensorflow.org/api_docs/python/tf/reduce_sum\" style=\"border-radius: 2px\">tf.reduce_sum</button>\n  <a class=\"btn btn-info\" href=\"https://www.tensorflow.org/api_docs/python/tf/train/Optimizer\" style=\"border-radius: 2px\">tf.train.Optimizer</button>\n</div>\n"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 7, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Construct a linear model, and give the result to variable called \"pred\" by using tf.add() and tf.multiply()\n# General equation: Y=A*X+b\npred = tf.add(tf.multiply(X, W), b)"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 8, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Calculate the mean squared error, and give the result to variable called \"cost\"\ncost = tf.reduce_sum(tf.pow(pred-Y, 2))/(2*n_samples)"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 9, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Create the Optimizer that implements the Gradient descent algorithm.\n# In this example, we are using the GradientDescentOptimizer() optimizer and minimize() operation.\n# Note, minimize() knows to modify W and b because Variable objects are trainable=True by default\noptimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 6. Initialize the variables"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 10, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Initialize the variables (i.e. assign their default value)\ninit = tf.global_variables_initializer()"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 7. Create the session\nAll the steps above we are building a graph in the TensorFlow, next, we are going to run the operations using the tf.Session.<br>\nIn this step, we need to create the session and run it with the initialized variables <em>(init)</em> first.<br>\n\n<a class=\"btn btn-info\" href=\"https://www.tensorflow.org/api_docs/python/tf/Session\" style=\"border-radius: 2px\">tf.Session</button>"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": 11, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "sess=tf.Session()\nsess.run(init)"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 8. Fit the training data\n<p>In this step, you need to:<br>\n- 1.run the session with training data fed in the model\n- 2.try to append the historical cost of model to <b>cost_history</b>.\n- 3.print the <em>W</em> and <em>b</em> every 20 epoch.\n</p>\n<small><small><em>(Tips: using the <b>for</b> loop will be helpful here.)</em></small></small>"
        }, 
        {
            "outputs": [
                {
                    "output_type": "stream", 
                    "text": "0 -0.214253 0.876489\n20 0.234301 0.944975\n40 0.233853 0.94814\n60 0.233408 0.951205\n80 0.232977 0.954177\n100 0.232558 0.957057\n120 0.232153 0.959848\n140 0.23176 0.962553\n160 0.231379 0.965176\n180 0.23101 0.967717\n200 0.230652 0.970181\n220 0.230305 0.972568\n240 0.229969 0.974883\n260 0.229643 0.977126\n280 0.229327 0.9793\n300 0.229021 0.981407\n320 0.228724 0.98345\n340 0.228437 0.985429\n360 0.228158 0.987348\n380 0.227888 0.989208\n400 0.227626 0.99101\n420 0.227373 0.992758\n440 0.227127 0.994451\n460 0.226888 0.996092\n480 0.226657 0.997683\n500 0.226433 0.999225\n520 0.226216 1.00072\n540 0.226006 1.00217\n560 0.225802 1.00357\n580 0.225604 1.00493\n600 0.225412 1.00625\n620 0.225227 1.00753\n640 0.225047 1.00877\n660 0.224872 1.00997\n680 0.224703 1.01113\n700 0.224539 1.01226\n720 0.22438 1.01336\n740 0.224226 1.01442\n760 0.224077 1.01544\n780 0.223933 1.01644\n800 0.223792 1.0174\n820 0.223657 1.01834\n840 0.223525 1.01925\n860 0.223397 1.02013\n880 0.223273 1.02098\n900 0.223154 1.0218\n920 0.223037 1.0226\n940 0.222925 1.02338\n960 0.222815 1.02413\n980 0.22271 1.02486\n", 
                    "name": "stdout"
                }
            ], 
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {}, 
            "source": "# Fit all training data\n# Please put your code here\nfor epoch in range(training_epochs):\n      sess.run(optimizer,feed_dict={X: train_X, Y: train_Y})\n      cost_history = np.append(cost_history,sess.run(cost,feed_dict={X: train_X, Y: train_Y}))\n\n      if epoch % 20 == 0:\n         print(epoch, sess.run(W),sess.run(b))"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 9. Plot the cost\nNow we have a trained Linear Regression model. We are now able to make predictions on unseen data. But first plot the cost as a function of number of iterations."
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# plotting using the Matplotlib, please complete the code here\n# The x-axis is the value of training_epochs, and the y-axis is the value of cost_history\nplt.figure(num=1, figsize=(20, 10))\nplt.plot(range(len(cost_history)),cost_history)\nplt.axis([0,training_epochs,0,np.max(cost_history)])\nplt.show()"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 10. Plot the prediction for training data"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Graphic display of the training data prediction\nplt.plot(train_X, train_Y, 'ro', label='Original data')\nplt.plot(train_X, sess.run(W)* train_X + sess.run(b), label='Fitted line')\nplt.legend()\nplt.show()"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 11. Calculate the MSE of traning result"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# MSE of the training result\n# First you need to assign the result to a variable, here we use \"pred_y\"\n# Also you need to print the MSE value\npred_y = sess.run(pred,feed_dict={X: train_X})\nmse = tf.reduce_mean(tf.square(pred_y - train_Y))\nprint(\"MSE: %.4f\" % sess.run(mse))"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 12. Make predictions on test dataset and calculate the mean square error\nIn this step, try to use the <b>test data</b> to make the prediction.<br>\n<em><small><small>(Reminder: train_X, train_Y, test_X, test_Y)</small></small></em>"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# Please put your code here\npred_y = sess.run(pred,feed_dict={X: test_X})\nmse = tf.reduce_mean(tf.square(pred_y - test_Y))\nprint(\"MSE: %.4f\" % sess.run(mse))"
        }, 
        {
            "metadata": {
                "collapsed": true
            }, 
            "cell_type": "markdown", 
            "source": "### 12. Plot the prediction for test data"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "# now make the predictions on the test dataset and calculate the mean square error\nfig, ax = plt.subplots()\nax.scatter(test_Y, pred_y)\nax.plot([test_Y.min(),test_Y.max()], [test_Y.min(), test_Y.max()], 'k--', lw=3)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()"
        }, 
        {
            "metadata": {}, 
            "cell_type": "markdown", 
            "source": "### 13. Remember to close the session"
        }, 
        {
            "outputs": [], 
            "cell_type": "code", 
            "execution_count": null, 
            "metadata": {
                "collapsed": true
            }, 
            "source": "sess.close()"
        }
    ], 
    "nbformat": 4, 
    "nbformat_minor": 2
}